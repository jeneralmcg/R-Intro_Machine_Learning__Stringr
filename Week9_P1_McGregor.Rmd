---
title: "Week 9 Practice #1"
author: "Jen McGregor"
output:
  prettydoc::html_pretty:
  theme: hpstr
  pdf_document: default
---

```{r, include = FALSE}
#templar::versions_multilingual()
```

```{r setup, include=FALSE}
library(tidyverse)
library(tidymodels)
library(kknn)
library(glmnet)
library(discrim)
```


# LDA

#### Code from lecture:

```{r, message = FALSE}
ins <- read_csv("https://www.dropbox.com/s/bocjjyo1ehr5auz/insurance.csv?dl=1")

ins <- ins %>%
  mutate(
    smoker = factor(smoker)
  ) %>%
  drop_na()
```

```{r include=FALSE}
testmodelwoohoo <- glm(smoker~.,family=binomial,data=ins)
summary(testmodelwoohoo)
```

```{r}
lda_mod <- discrim_linear() %>%
  set_engine("MASS") %>%
  set_mode("classification")
```

```{r}
lda_fit_1 <- lda_mod %>%
  fit(smoker ~ charges, data = ins)

lda_fit_1$fit %>% summary()
```

```{r}
lda_fit_1 
```

```{r}
preds <- lda_fit_1 %>% predict(ins)

ins <- ins %>%
  mutate(
    pred_smoker = preds$.pred_class
  )

ins %>%
  accuracy(truth = smoker,
           estimate = pred_smoker)
```

```{r}
lda_fit_2 <- lda_mod %>%
  fit(smoker ~ charges + age, data = ins)

lda_fit_2
lda_fit_2$fit$scaling
```

```{r, echo = FALSE}
ins %>%
  ggplot(aes(x = charges, y = age, color = smoker)) +
  geom_point()
```

```{r}
lda_fit_2
my_slope = lda_fit_2$fit$scaling[1]/(-1*lda_fit_2$fit$scaling[2])
```

```{r, echo = FALSE}
ins %>%
  ggplot(aes(x = charges, y = age, color = smoker)) +
  geom_point() +
  geom_abline(aes(slope = my_slope, intercept = 0))
```

```{r}
preds <- lda_fit_2 %>% predict(ins)

ins <- ins %>%
  mutate(
    pred_smoker = preds$.pred_class
  )

ins %>%
  accuracy(truth = smoker,
           estimate = pred_smoker)
```

### Finding Best LDA Model

```{r set_mod}
lda_mod <- discrim_linear() %>%
  set_engine("MASS") %>%
  set_mode("classification")
```

```{r, LDA Model 1}
lda_rec1 <- recipe(smoker~charges,data=ins) %>%
  step_normalize(charges)

lda_wflow1 <- workflow() %>%
  add_recipe(lda_rec1) %>%
  add_model(lda_mod)

ins_cv <- vfold_cv(ins, v = 10)

lda_1_cv <- lda_mod %>%
  fit_resamples(smoker ~ charges,
                resamples = ins_cv)

lda_1_cv %>% collect_metrics()
```

```{r, LDA Model 2}
lda_rec2 <- recipe(smoker~charges+age,data=ins) %>%
  step_normalize(charges,age)

lda_wflow2 <- workflow() %>%
  add_recipe(lda_rec2) %>%
  add_model(lda_mod)

ins_cv <- vfold_cv(ins, v = 10)

lda_2_cv <- lda_mod %>%
  fit_resamples(smoker ~ charges+age,
                resamples = ins_cv)

lda_2_cv %>% collect_metrics()
```


```{r, LDA Model 3}
lda_rec3 <- recipe(smoker~age+bmi+charges,data=ins) %>%
  step_normalize(age,bmi,charges)

lda_wflow3 <- workflow() %>%
  add_recipe(lda_rec3) %>%
  add_model(lda_mod)

ins_cv <- vfold_cv(ins, v = 10)

lda_3_cv <- lda_mod %>%
  fit_resamples(smoker ~ age+bmi+charges,
                resamples = ins_cv)

lda_3_cv %>% collect_metrics()
```

```{r, LDA Model 4}
lda_rec4 <- recipe(smoker~age+bmi+charges+sex,data=ins) %>%
  step_normalize(age,bmi,charges) %>%
  step_dummy(sex)

lda_wflow4 <- workflow() %>%
  add_recipe(lda_rec4) %>%
  add_model(lda_mod)

ins_cv <- vfold_cv(ins, v = 10)

lda_4_cv <- lda_mod %>%
  fit_resamples(smoker ~ age+bmi+charges,
                resamples = ins_cv)

lda_4_cv %>% collect_metrics()
```


#### Find the best LDA model to predict smoker status. 

The best LDA model to predict smoker status is model 3, which uses age, bmi, and charges as predictors. Its cross-validated accuracy metric is 0.9373150.  

#### How does it compare to the Logistic Regression and KNN approaches?

Citation Key: 
  
  * **LDA M3** = LDA Model 3
  
  * **KNN M3** = KNN Model 3
  
  * **Logit M3** = Logistic Regression Model 3

##### Cross-Validated Accuracy Results
  
Metric  | LDA M1  | LDA M2   | LDA M3  | LDA M4  | Winner |
--------| ------  | -------- |---------|---------|--------|
Accuracy|0.9209831|0.9119979 |0.9373150|0.9372093| LDA M3 |

Metric  | KNN M1  | KNN M2   | KNN M3  | KNN M4  | Winner |
--------| ------  | -------- |---------|---------|--------|
Accuracy|0.9488901|0.9465645 |0.9651691|0.9582452| KNN M3 |

Metric  | Logit M1| Logit M2| Logit M3 | Logit M4 | Winner | 
--------|---------| ------- |----------|----------|--------|
Accuracy|0.9210359|0.9119450|0.9374736 |0.9420190 |Logit M4|

##### Best Model

Metric  | LDA M3  | KNN M3  | Logit M4 | Winner | 
--------|---------| ------- |----------|--------|
Accuracy|0.9373150|0.9651691|0.9420190 |KNN M3  |

# KNN

### Finding Best KNN Model

```{r, Set KNN Mod}
knn_mod_tune <- nearest_neighbor(neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("classification")
```

```{r, KNN Model 1}
knn_rec1 <- recipe(smoker~charges,data=ins) %>%
  step_normalize(charges)

knn_wflow <- workflow() %>%
  add_recipe(knn_rec1) %>%
  add_model(knn_mod_tune)

ins_cv <- vfold_cv(ins, v = 10)

k_grid <- grid_regular(neighbors(c(1,50)), 
                       levels = 25)

knn_grid_search <-
  tune_grid(
    knn_wflow,
    resamples = ins_cv,
    grid = k_grid
  )

knn_grid_search %>% 
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  slice_max(mean)
```

```{r, KNN Model 2}
knn_rec2 <- recipe(smoker~charges+age,data=ins) %>%
  step_normalize(charges,age)

knn_wflow <- workflow() %>%
  add_recipe(knn_rec2) %>%
  add_model(knn_mod_tune)

ins_cv <- vfold_cv(ins, v = 10)

k_grid <- grid_regular(neighbors(c(1,50)), 
                       levels = 25)

knn_grid_search <-
  tune_grid(
    knn_wflow,
    resamples = ins_cv,
    grid = k_grid
  )


knn_grid_search %>% 
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  slice_max(mean)
```

```{r, KNN Model 3}
knn_rec3 <- recipe(smoker~age+bmi+charges,data=ins) %>%
  step_normalize(charges,age,bmi)

knn_wflow <- workflow() %>%
  add_recipe(knn_rec3) %>%
  add_model(knn_mod_tune)

ins_cv <- vfold_cv(ins, v = 10)

k_grid <- grid_regular(neighbors(c(1,50)), 
                       levels = 25)

knn_grid_search <-
  tune_grid(
    knn_wflow,
    resamples = ins_cv,
    grid = k_grid
  )

knn_grid_search %>% 
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  slice_max(mean)
```

```{r, KNN Model 4}
knn_rec4 <- recipe(smoker~age+bmi+charges+sex,data=ins) %>%
  step_normalize(charges,age,bmi) %>%
  step_dummy(sex)

knn_wflow <- workflow() %>%
  add_recipe(knn_rec4) %>%
  add_model(knn_mod_tune)

ins_cv <- vfold_cv(ins, v = 10)

k_grid <- grid_regular(neighbors(c(1,50)), 
                       levels = 25)

knn_grid_search <-
  tune_grid(
    knn_wflow,
    resamples = ins_cv,
    grid = k_grid
  )

knn_grid_search %>% 
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  slice_max(mean)
```

# Logistic Regression

### Finding Best Logistic Regression Model

```{r}
logit_mod <- logistic_reg() %>%
  set_mode("classification") %>%
  set_engine("glm")
```

```{r, Logistic Model 1}
logit_rec1 <- recipe(smoker~charges,data=ins) %>%
  step_normalize(charges)

logit_wflow1 <- workflow() %>%
  add_recipe(logit_rec1) %>%
  add_model(logit_mod)

ins_cv <- vfold_cv(ins, v = 10)

logit_1_cv <- lda_mod %>%
  fit_resamples(smoker ~ charges,
                resamples = ins_cv)

logit_1_cv %>% collect_metrics()
```

```{r, Logistic Model 2}
logit_rec2 <- recipe(smoker~charges+age,data=ins) %>%
  step_normalize(charges,age)

logit_wflow2 <- workflow() %>%
  add_recipe(logit_rec2) %>%
  add_model(logit_mod)

ins_cv <- vfold_cv(ins, v = 10)

logit_2_cv <- lda_mod %>%
  fit_resamples(smoker ~ charges+age,
                resamples = ins_cv)

logit_2_cv %>% collect_metrics()
```

```{r, Logistic Model 3}
logit_rec3 <- recipe(smoker~charges+age+bmi,data=ins) %>%
  step_normalize(charges,age,bmi)

logit_wflow3 <- workflow() %>%
  add_recipe(logit_rec3) %>%
  add_model(logit_mod)

ins_cv <- vfold_cv(ins, v = 10)

logit_3_cv <- lda_mod %>%
  fit_resamples(smoker ~ charges+age+bmi,
                resamples = ins_cv)

logit_3_cv %>% collect_metrics()
```

```{r, Logistic Model 4}
logit_rec4 <- recipe(smoker~charges+age+bmi+sex,data=ins) %>%
  step_normalize(charges,age,bmi) %>%
  step_dummy(sex)

logit_wflow4 <- workflow() %>%
  add_recipe(logit_rec4) %>%
  add_model(logit_mod)

ins_cv <- vfold_cv(ins, v = 10)

logit_4_cv <- lda_mod %>%
  fit_resamples(smoker ~ charges+age+bmi+sex,
                resamples = ins_cv)

logit_4_cv %>% collect_metrics()
```


# Quadratic Discriminant Analysis

#### Code from lecture:

```{r qda_mod}
qda_mod <- discrim_regularized(frac_common_cov = 0) %>% 
             set_engine('klaR') %>% 
             set_mode('classification')
```

```{r, echo = FALSE}
dat <- tibble(
  A = rnorm(100, 10, 5),
  B = rnorm(100, 15, 1)
) %>%
  pivot_longer(everything(),
               values_to = "val",
               names_to = "Class")

ggplot(dat, aes(x = val, fill = Class)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 11)
```


```{r, echo = FALSE}
dat <- tibble(
  V1 = c(rnorm(100, 10, 5), rnorm(100, 37, 18)),
  V2 = c(rnorm(100, 15, 1), rnorm(100, 30, 9)),
  Class = factor(c(rep("A", 100), rep("B", 100)))
) 

dat %>%
  ggplot(aes(x = V1, y = V2, col = Class)) +
  geom_point()
```


```{r, echo = FALSE}
qda_wflow <- workflow() %>%
  add_recipe(recipe(Class ~ V1 + V2, data = dat)) %>%
  add_model(qda_mod) %>%
  fit(dat)

# qda_wflow %>%
#   horus::viz_decision_boundary(dat)
```

#### Find the best QDA model to predict smoker status.

The best QDA model to predict smoker status is model 3, which uses age, bmi, and charges as predictors. Its cross-validated accuracy metric is 0.9397992. 

##### Cross-Validated Accuracy Results

Metric  | QDA M1  | QDA M2   | QDA M3  | QDA M4  | Winner
--------| ------  | -------- |---------|---------|-------
Accuracy|0.9209831|0.9049154 |0.9397992|0.9396406|QDA M3

#### How does it compare to the LDA, Logistic Regression, and KNN approaches?

The best QDA Model, Model 3 fits in well with the other top LDA, Logistic, and KNN models. However, KNN Model 3 remains the best model in terms of cross-validated accuracy. 

Metric  | LDA M3  | KNN M3  | Logit M4 | QDA M3  | Winner
--------|---------| ------- |----------|---------|--------
Accuracy|0.9373150|0.9651691|0.9420190 |0.9397992| KNN M3 

# Metrics

```{r}
qda_mod <- discrim_regularized(frac_common_cov = 0) %>% 
             set_engine('klaR') %>% 
             set_mode('classification')
```

```{r, QDA Model 1}
qda_rec1 <- recipe(smoker~charges,data=ins) %>%
  step_normalize(charges)

qda_wflow1 <- workflow() %>%
  add_recipe(qda_rec1) %>%
  add_model(qda_mod)

ins_cv <- vfold_cv(ins, v = 10)

qda_1_cv <- lda_mod %>%
  fit_resamples(smoker ~ charges,
                resamples = ins_cv)

qda_1_cv %>% collect_metrics()
```

```{r, QDA Model 2}
qda_rec2 <- recipe(smoker~charges+age,data=ins) %>%
  step_normalize(charges,age)

qda_wflow2 <- workflow() %>%
  add_recipe(qda_rec2) %>%
  add_model(qda_mod)

ins_cv <- vfold_cv(ins, v = 10)

qda_2_cv <- lda_mod %>%
  fit_resamples(smoker ~ charges+age,
                resamples = ins_cv)

qda_2_cv %>% collect_metrics()
```

```{r, QDA Model 3}
qda_rec3 <- recipe(smoker~charges+age+bmi,data=ins) %>%
  step_normalize(charges,age,bmi)

qda_wflow3 <- workflow() %>%
  add_recipe(qda_rec3) %>%
  add_model(qda_mod)

ins_cv <- vfold_cv(ins, v = 10)

qda_3_cv <- lda_mod %>%
  fit_resamples(smoker ~ charges+age+bmi,
                resamples = ins_cv)

qda_3_cv %>% collect_metrics()
```

```{r, QDA Model 4}
qda_rec4 <- recipe(smoker~charges+age+bmi+sex,data=ins) %>%
  step_normalize(charges,age,bmi) %>%
  step_dummy(sex)

qda_wflow4 <- workflow() %>%
  add_recipe(qda_rec4) %>%
  add_model(qda_mod)

ins_cv <- vfold_cv(ins, v = 10)

qda_4_cv <- lda_mod %>%
  fit_resamples(smoker ~ charges+age+bmi+sex,
                resamples = ins_cv)

qda_4_cv %>% collect_metrics()
```
